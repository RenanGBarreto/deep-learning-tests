{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ª Lista de Exercícios - Deep Learning - Questão 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Questão 1](imgs/questoes/q2.png \"Questão 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Criação de um dataset com 16 pontos e variação de +/- 20%:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[0.09161826113661227, 0.08096895155806333, 0.0673314054643124],\n",
       "  [0.0113760497154086, -0.008958776109398393, 0.9520910290397203],\n",
       "  [-0.0007728094209140668, 1.0885474709665206, 0.03202434039390439],\n",
       "  [0.026019273158738022, 1.0905755731202578, 0.905781572693711],\n",
       "  [1.0844615618817437, -0.045155062461032805, 0.03309418343356514],\n",
       "  [1.050105577830106, 0.03577607078369854, 1.0756023618760506],\n",
       "  [0.974367210986845, 0.9652035488099325, 0.02819396504470395],\n",
       "  [1.0405190710334131, 1.0249462016178847, 1.0564494138394127],\n",
       "  [-0.09658736772080652, -0.09514597408118447, 0.014258047050399326],\n",
       "  [0.023469130286267206, -0.03262718230954118, 1.0802703345695897],\n",
       "  [-0.020563184757433618, 1.071777280965237, 0.08850096151005012],\n",
       "  [-0.04576353271061698, 0.9584121279403071, 0.9830784122707754],\n",
       "  [0.9276604507039399, -0.07193008595950848, -0.07724120193819262],\n",
       "  [0.9106938730458676, 0.05973328303561301, 1.0504125913913651],\n",
       "  [1.0427053529986223, 0.9547268463911157, 0.007634170996733469],\n",
       "  [0.9726599520005701, 1.0998856193251063, 0.9627817667628856]],\n",
       " [0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def randomizeArrayData(arr, variation=0.1):\n",
    "    \"\"\" \n",
    "    Adiciona uma variação aleatoria em uma array de floats \n",
    "    \"\"\"\n",
    "    \n",
    "    for i in range(len(arr)):\n",
    "        arr[i] = arr[i] + (np.random.random()-0.5)*variation\n",
    "        \n",
    "    return arr\n",
    "\n",
    "def criaDataset(n, variation=0.1):\n",
    "    \"\"\" \n",
    "    Cria um conjunto de exemplos para a questão 1. Classificação de arestas em um cubo \n",
    "    \"\"\"\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    # Crie n/8 exemplos para cada classe\n",
    "    for i in range(math.ceil(n/8)):\n",
    "        X.append(randomizeArrayData([0, 0, 0], variation)) \n",
    "        Y.append(0)\n",
    "        X.append(randomizeArrayData([0, 0, 1], variation)) \n",
    "        Y.append(1)\n",
    "        X.append(randomizeArrayData([0, 1, 0], variation)) \n",
    "        Y.append(2)\n",
    "        X.append(randomizeArrayData([0, 1, 1], variation)) \n",
    "        Y.append(3)\n",
    "        X.append(randomizeArrayData([1, 0, 0], variation)) \n",
    "        Y.append(4)\n",
    "        X.append(randomizeArrayData([1, 0, 1], variation)) \n",
    "        Y.append(5)\n",
    "        X.append(randomizeArrayData([1, 1, 0], variation)) \n",
    "        Y.append(6)\n",
    "        X.append(randomizeArrayData([1, 1, 1], variation)) \n",
    "        Y.append(7)\n",
    "        \n",
    "    return X, Y\n",
    "\n",
    "print(\"Criação de um dataset com 16 pontos e variação de +/- 20%:\\n\")\n",
    "display(criaDataset(16, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Neuron'>: {'weights': array([ 0.55930696,  0.10581092]), 'bias': 0.9283526622471622, 'inputs': [<__main__.Neuron object at 0x7fbac7cd01d0>, <__main__.Neuron object at 0x7fbac7cd0be0>], 'lr': 0.1}\n",
      "Matriz de Confusão:\n",
      "[[ 0 12  0  0  0  0  0 13]\n",
      " [ 0 25  0  0  0  0  0  0]\n",
      " [ 0 25  0  0  0  0  0  0]\n",
      " [ 0 25  0  0  0  0  0  0]\n",
      " [ 0 25  0  0  0  0  0  0]\n",
      " [ 0 25  0  0  0  0  0  0]\n",
      " [ 0 25  0  0  0  0  0  0]\n",
      " [ 0 25  0  0  0  0  0  0]]\n",
      "F1 Score:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        25\n",
      "          1       0.13      1.00      0.24        25\n",
      "          2       0.00      0.00      0.00        25\n",
      "          3       0.00      0.00      0.00        25\n",
      "          4       0.00      0.00      0.00        25\n",
      "          5       0.00      0.00      0.00        25\n",
      "          6       0.00      0.00      0.00        25\n",
      "          7       0.00      0.00      0.00        25\n",
      "\n",
      "avg / total       0.02      0.12      0.03       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/goldmine/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import spline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pylab\n",
    "\n",
    "\n",
    "# derivada da relu: 0 se menor que zero, e 1 se maior que zero\n",
    "\n",
    "\n",
    "class Neuron:\n",
    "\n",
    "    def __init__(self, inputs, lr = 0.01):\n",
    "        \n",
    "        # Os inputs pode ser um array de neuros ou um escalar\n",
    "        if (isinstance(inputs, list)):\n",
    "            self.weights = np.random.rand(len(inputs))\n",
    "        else:\n",
    "            self.weights = np.random.rand(inputs)\n",
    "        \n",
    "        self.bias = np.random.random() + 0.1\n",
    "        self.inputs = inputs\n",
    "        self.lr = lr if lr > 0 else 0.0001\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__)\n",
    "\n",
    "\n",
    "    def vj(self, x) :\n",
    "        if (isinstance(self.inputs, list)):            \n",
    "            signals = []            \n",
    "            for i in range(len(self.inputs)):\n",
    "                signals.append( self.inputs[i].forward(x))             \n",
    "            return np.dot(self.weights, signals) + self.bias          \n",
    "        else:\n",
    "            return np.dot(self.weights, x) + self.bias\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.predict(self.activation( self.vj(x) ))\n",
    "\n",
    "\n",
    "    def backward(self, x, y, soma=None): \n",
    "\n",
    "        somaPonderada = 0\n",
    "        \n",
    "        y_pred = self.forward(x)\n",
    "        \n",
    "        for idx in range(len(self.weights)):\n",
    "            \n",
    "            gradient = 0\n",
    "\n",
    "            if (soma == None): \n",
    "                error = y - y_pred\n",
    "                gradient = error * self.activation_derivative( self.vj(x) )\n",
    "            else:\n",
    "                gradient = self.activation_derivative( self.vj(x) ) * soma\n",
    "       \n",
    "            somaPonderada = somaPonderada + gradient*self.weights[idx]\n",
    "            \n",
    "            self.weights[idx] = self.weights[idx] + self.lr * x[idx] *  gradient\n",
    "            \n",
    "        if (isinstance(self.inputs, list)): \n",
    "            for i in range(len(self.inputs)):\n",
    "                self.inputs[i].backward(x, y, soma=somaPonderada)\n",
    "            \n",
    "    def activation(self, x):\n",
    "        return 0 if (x < 0) else x\n",
    "\n",
    "    def activation_derivative(self, x):\n",
    "        return 1 if (x >= 0) else 0\n",
    "        \n",
    "    def adjustWeights(self, x, error):            \n",
    "        self.bias = self.bias + error*self.lr        \n",
    "        for idx in range(len(self.weights)):\n",
    "            self.weights[idx] = self.weights[idx] + error*self.lr*x[idx]\n",
    "\n",
    "    def predict(self, out):\n",
    "        \"\"\"\n",
    "        Função que discretiza a saída\n",
    "        Parâmetro: y - saída do neurònio\n",
    "        \"\"\"\n",
    "        if out < 0:\n",
    "            return 0\n",
    "        elif out > 7:\n",
    "            return 7\n",
    "        else:\n",
    "            return round(out)\n",
    "        \n",
    "# TESTES\n",
    "X, Y = criaDataset(200, 0.1)   \n",
    "\n",
    "n_inputs = len(X[0])\n",
    "        \n",
    "layer1 = [ Neuron(n_inputs, lr=0.1) , Neuron(n_inputs, lr=0.1)]\n",
    "    \n",
    "layer2 = [ Neuron(layer1, lr=0.1)] \n",
    "\n",
    "network = layer2\n",
    "\n",
    "#y_pred = network[0].forward(X[0])\n",
    "#print(y_pred)\n",
    "\n",
    "perceptron = network[0]\n",
    "\n",
    "# perceptron = Neuron(len(X[0]))\n",
    "\n",
    "print(perceptron)\n",
    "\n",
    "for epoch in range(1000):\n",
    "    erros_interacao = []\n",
    "    for i in range(len(X)):\n",
    "        y_pred = perceptron.forward(X[i])\n",
    "        error = Y[i] - y_pred\n",
    "        erros_interacao.append(error*error)\n",
    "        perceptron.backward(X[i], Y[i])\n",
    "    erro_medio = np.average(erros_interacao)\n",
    "    #print(erro_medio)\n",
    "\n",
    "# Preenche o array de saidas preditas\n",
    "y_pred = []\n",
    "for j in range(len(X)):\n",
    "    y_pred.append(perceptron.forward(X[j]))\n",
    "\n",
    "# Métricas de Avaliação\n",
    "print('Matriz de Confusão:')\n",
    "print(confusion_matrix(Y, y_pred))\n",
    "print('F1 Score:')\n",
    "print(classification_report(Y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação do Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import spline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(num_inputs): \n",
    "    \"\"\"\n",
    "    Função que inicializa os pesos e bias aleatoriamente utilizando numpy\n",
    "    Parâmetro: num_inputs - quantidade de entradas X\n",
    "    Retorna: w,b - pesos e bias da rede inicializados\n",
    "    \"\"\"\n",
    "    w = np.random.rand(num_inputs) - 0.5\n",
    "    b =  np.random.random() - 0.5       \n",
    "    return w,b\n",
    "\n",
    "# Teste da função weight_init:\n",
    "print(weight_init(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_func(func_type, z):\n",
    "    \"\"\"\n",
    "    Função que implementa as funções de ativação mais comuns\n",
    "    Parãmetros: func_type - uma string que contém a função de ativação desejada\n",
    "                z - vetor com os valores de entrada X multiplicado pelos pesos\n",
    "    Retorna: saída da função de ativação\n",
    "    \"\"\"\n",
    "    if func_type == 'sigmoid':\n",
    "        return 1/(1 + np.exp(-z))\n",
    "    elif func_type == 'tanh':\n",
    "        return math.sinh(z)/math.cosh(z)\n",
    "    elif func_type == 'relu':\n",
    "        return 0 if (z<0) else z\n",
    "    elif func_type == 'linear':\n",
    "        return z\n",
    "    elif func_type == 'degrau':\n",
    "        return 0 if (z < 0) else  1\n",
    "    \n",
    "def visualizeActivationFunc(z, func_type):\n",
    "    pylab.rcParams['figure.figsize'] = (10.0, 5.0)\n",
    "    z = np.arange(-5., 5., 0.2)\n",
    "    func = []\n",
    "    for i in range(len(z)):\n",
    "        func.append(activation_func(func_type, z[i]))\n",
    "    \n",
    "    pylab.rcParams['figure.figsize'] = (5.0, 2.0)\n",
    "    plt.plot(z,func)\n",
    "    plt.title(\"Função: \"+func_type)\n",
    "    plt.xlabel('Entrada')\n",
    "    plt.ylabel('Valores de Saída')\n",
    "    plt.show()\n",
    "\n",
    "# Testa as funções de ativação\n",
    "visualizeActivationFunc(np.arange(-5., 5., 0.2), 'degrau')\n",
    "visualizeActivationFunc(np.arange(-5., 5., 0.2), 'sigmoid')\n",
    "visualizeActivationFunc(np.arange(-5., 5., 0.2), 'tanh')\n",
    "visualizeActivationFunc(np.arange(-5., 5., 0.2), 'relu')\n",
    "visualizeActivationFunc(np.arange(-5., 5., 0.2), 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w,b,X):\n",
    "    \"\"\"\n",
    "    Função que implementa a etapa forward propagate do neurônio\n",
    "    Parâmetros: w - pesos\n",
    "                b - bias\n",
    "                X - entradas\n",
    "    \"\"\"\n",
    "    z = np.dot(w,X)+b\n",
    "    out = activation_func('relu', z)\n",
    "    return out\n",
    "\n",
    "# Teste: forward\n",
    "x = (1, 1, 1)\n",
    "w,b = weight_init(3)\n",
    "print(\"X: \", x)\n",
    "print(\"Pesos: \", w)\n",
    "print(\"Bias: \", b)\n",
    "print(\"Y: \", forward(w,b,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(out):\n",
    "    \"\"\"\n",
    "    Função que discretiza a saída\n",
    "    Parâmetro: y - saída do neurònio\n",
    "    \"\"\"\n",
    "    if out < 0:\n",
    "        return 0\n",
    "    elif out > 7:\n",
    "        return 7\n",
    "    else:\n",
    "        return round(out)\n",
    "\n",
    "# Teste: predict\n",
    "print (\"Entrada=1.1 -> Saida=\", predict(1.1))\n",
    "print (\"Entrada=4.5 -> Saida=\", predict(4.5))\n",
    "print (\"Entrada=70.0 -> Saida=\", predict(70.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x, y, num_interaction, learning_rate):\n",
    "    \"\"\"\n",
    "    Função que implementa o loop do treinamento \n",
    "    Parâmetros: x - entrada da rede \n",
    "                y - rótulos/labels\n",
    "                num_interaction - quantidade de interações desejada para a rede convergir\n",
    "                learning_rate - taxa de aprendizado para cálculo do erro\n",
    "    \"\"\"\n",
    "    training_interation = []\n",
    "    training_erro = []\n",
    "    \n",
    "    #Passo 1 - Inicie os pesos e bias (~1 linha)\n",
    "    w,b = weight_init(len(x[0]))\n",
    "    #Passo 2 - Loop por X interações\n",
    "    for i in range(num_interaction):\n",
    "        \n",
    "        # Ajuda no calculo do erro médio quadrado\n",
    "        erros_interacao = []\n",
    "        \n",
    "        for j in range(len(x)): # para cada exemplo\n",
    "            \n",
    "            # Passo 3 -  calcule a saída do neurônio (~1 linha)\n",
    "            y_calc = predict(forward(w,b,x[j]))\n",
    "            \n",
    "            # Passo 4 - calcule o erro entre a saída obtida e a saída desejada nos rótulos/labels (~1 linha)\n",
    "            erro = y[j] - y_calc  \n",
    "            \n",
    "            # Adiciona o erro quadrado dessa instancia\n",
    "            erros_interacao.append(erro*erro)\n",
    "            \n",
    "            # Ajusta os pesos e bias\n",
    "            for idx in range(len(w)):\n",
    "                w[idx] = w[idx] + erro*learning_rate*x[j][idx]            \n",
    "\n",
    "            b = b + erro*learning_rate\n",
    "        \n",
    "        # Calcula o erro médio dessa interação\n",
    "        erro_medio = np.average(erros_interacao)\n",
    "        \n",
    "        training_interation.append(i)\n",
    "        training_erro.append(erro_medio) \n",
    "        \n",
    "        # Apenas para garantir que pare quando o erro atingir um valor limite mínimo\n",
    "        if (erro_medio < 0.00001):\n",
    "            print(\"Finalizado na interação %d visto que o erro médio já se tornou muito pequeno %f\" % (i, erro_medio))\n",
    "            break;\n",
    "    \n",
    "    # Cria um grafico com os dados sobre o erro de treinamento\n",
    "    pylab.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "    plt.plot(training_interation, training_erro)\n",
    "    plt.xlabel('Interação')\n",
    "    plt.ylabel('Erro médio quadrado')\n",
    "    plt.show()\n",
    "    \n",
    "    return w,b\n",
    "\n",
    "def validar(w,b,x,y):\n",
    "\n",
    "    # Preenche o array de saidas preditas\n",
    "    y_pred = []\n",
    "    for j in range(len(x)):\n",
    "        y_pred.append(predict(forward(w,b,x[j])))\n",
    "       \n",
    "    # Métricas de Avaliação\n",
    "    print('Matriz de Confusão:')\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print('F1 Score:')\n",
    "    print(classification_report(y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação dos Datasets de Treinamento e Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = criaDataset(800, 0.1)\n",
    "X_val, Y_val = criaDataset(200, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainamento do Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, b = perceptron(X_train, Y_train, 1000, 0.001)\n",
    "print(\"Pesos Aprendidos:\", w, \"\\nBias Aprendido:\", b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjunto de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar(w, b, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjunto de Validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validar(w, b, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
